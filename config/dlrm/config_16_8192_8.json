{
  "num_gpus": 128,
  "gpu_name": "A100",
  "tensor_parallel_size": 4,
  "data_parallel_size": 8,
  "pipeline_parallel_size": 4,
  "global_batch_size": 256000,
  "micro_batch_size": 1,
  "num_layers": 16,
  "hidden_size": 8192,
  "num_attention_heads": 8,
  "max_length": 1024,
  "use_gradient_bucket": false,
  "use_checkpoint": true,
  "pipeline_scheduling": "1f1b",
  "inter_node_bandwidth": 25.6,
  "intra_node_bandwidth": 38.4,
  "node_size": 16,
  "trace_path": "trace/"
}