{
  "num_gpus": 2048,
  "gpu_name": "A100",
  "tensor_parallel_size": 16,
  "data_parallel_size": 16,
  "pipeline_parallel_size": 8,
  "global_batch_size": 2048,
  "micro_batch_size": 1,
  "num_layers": 128,
  "hidden_size": 512,
  "num_attention_heads": 16,
  "max_length": 2048,
  "use_gradient_bucket": false,
  "use_checkpoint": true,
  "pipeline_scheduling": "1f1b",
  "inter_node_bandwidth": 409.6,
  "intra_node_bandwidth": 614.4,
  "node_size": 256,
  "trace_path": "trace/"
}